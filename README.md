# deepseek-m1-optimized

## Fine-tuned DeepSeek Coder on Mac M1 & Kubernetes Deployment



This repository contains a fine-tuned version of the DeepSeek Coder model, optimized for Mac M1 and deployed on a Kubernetes cluster. The model is fine-tuned using QLoRA and trained with a Chain-of-Thought dataset for improved reasoning capabilities.



### ğŸš€ Features

â€¢ Fine-tuned DeepSeek Coder 6.7B model

â€¢ Optimized for Apple M1/M2 (Metal backend)

â€¢ Supports QLoRA for low-memory adaptation

â€¢ Deployment via Docker & Kubernetes

â€¢ Benchmarking script for performance evaluation

### ğŸ“¥ Installation & Setup



1. Clone the Repository


```
git clone https://github.com/tawrid/deepseek-finetuned.git

cd deepseek-finetuned
```
2. Install Dependencies



Ensure you have Homebrew installed, then run:

```
brew update && brew upgrade
brew install git python3 wget
pip3 install --upgrade pip
pip3 install torch torchvision torchaudio 
```
transformers accelerate datasets bitsandbytes peft

3. Install Ollama (Mac M1)



Since ollama is only available via a ZIP file, install it manually:

```
curl -o ollama.zip https://ollama.com/download/Ollama-darwin.zip
unzip ollama.zip -d /Applications
```
### ğŸ”¥ Fine-Tuning the Model



Run the fine-tuning script using:

```
python3 fine_tune_deepseek.py
```
#### Common Errors & Fixes

â€¢ bitsandbytes was compiled without GPU support

â†’ Solution: Use pip install bitsandbytes --no-cache-dir

â€¢ Dataset column mismatch (No columns match model's forward method)

â†’ Solution: Add remove_unused_columns=False in TrainingArguments.

### ğŸ Benchmarking Performance



Test the modelâ€™s response time using:

```
python3 benchmark_deepseek.py
```
Example Output

Prompt: Solve 24 Ã— 17 using step-by-step...
Time: 2.13 seconds
Prompt: Explain recursion in Python...
Time: 1.95 seconds

âœ… Average response time: 2.04 seconds


### ğŸ“¦ Docker & Kubernetes Deployment



1. Build & Load Docker Image

````
docker build -t deepseek-finetuned .
````
For Minikube, load the image:
```
minikube image load deepseek-finetuned
````
2. Deploy on Kubernetes
```
kubectl apply -f deepseek_deployment.yaml
kubectl apply -f deepseek_service.yaml
kubectl get services -n deepseek
```

If you encounter validation errors, disable validation:

```
kubectl apply -f deepseek_deployment.yaml --validate=false
```

3. Access the Model via API



Once deployed, check the running service:

```
kubectl get services -n deepseek
```
Then, send a request:

```
curl -X POST http://<SERVICE_IP>:<PORT>/generate \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Explain quantum computing"}'
```
### ğŸ“œ Repository Structure

```
ğŸ“‚ deepseek-finetuned
â”œâ”€â”€ fine_tune_deepseek.py   # Fine-tuning script
â”œâ”€â”€ benchmark_deepseek.py            # Benchmarking script
â”œâ”€â”€ Dockerfile              # Docker configuration
â”œâ”€â”€ deepseek_deployment.yaml # Kubernetes deployment
â”œâ”€â”€ deepseek_service.yaml   # Kubernetes service
â””â”€â”€ README.md               # This file
```

### ğŸ›  Troubleshooting



1. How to check if Docker image is created?

```
docker images | grep deepseek-finetuned
```

2. Mac storage is full (df -h shows 100% disk usage)

â€¢ Remove unused Docker containers:

```
docker system prune -a
```


â€¢ Clear unnecessary files:

```rm -rf ~/Library/Caches/*
```
### ğŸ¤– Contributing



Feel free to fork this repository, create a pull request, or open an issue if you find any bugs or improvements.

### ğŸ“„ License



This project is licensed under the MIT License.

This README provides clear steps for installation, fine-tuning, benchmarking, and Kubernetes deployment while also covering common errors and fixes. Let me know if you need any modifications! ğŸš€